import pandas as pd
import numpy as np
import mglearn, os

import matplotlib as mpl
import matplotlib.pyplot as plt
import image

# 1. 붓꽃iris 데이터셋
# 2. 두 개의 특성을 가진 forge 데이터셋은 인위적으로 만든 이진 분류 데이터셋
# 3. 위스콘신 유방암 Wisconsin Breast Cancer 데이터셋
# 4. 회귀 분석용 실제 데이터셋으로는 보스턴 주택가격 Boston Housing 데이터셋
# 5. 선형 회귀(최소제곱법)을 위한 wave 데이터셋.  n_samples = 40
# 6. 세 개의 클래스를 가진 간단한 blobs 데이터셋
# 7. scikit-learn에 구현된 나이브 베이즈 분류기는 GaussianNB, BernoulliNB, MultinomialNB 세가지
# 8. 메모리 가격 동향 데이터 셋 ram_prices
# 9. 두 개의 클래스를 가진 2차원 데이터셋 two_moons
# 10. 두 개의 클래스를 가진 2차원 데이터셋 make_handcrafted
# 11. 두 개의 클래스를 가진 2차원 데이터셋 make_circles
# 12. 뉴스그룹 데이터
# 13. 동물트리

# 1. 히스토그램
# 2. 산점도
# 3. n_neighbors 변화에 따른 결정 경계 
# 4. n_neighbors 변화에 따른 훈련 정확도와 테스트 정확도
# 5. 특성공학
# 6. 학습곡선
# 7. 결정 트리 분석
# 8. 

# 1. k-최근접 이웃 알고리즘 : 분류, 회귀
#    작은 데이터셋일 경우, 기본 모델로서 좋고 설명하기 쉬움
# 2. 선형모델 : 최소제곱, 릿지, 라쏘, 선형분류모델(로지스틱, 서포트벡터머신), 다중분류 선형모델
#    첫 번째로 시도할 알고리즘. 대용량 데이터셋 가능. 고차원 데이터에 가능
# 3. 나이브 베이즈 분류기
#    분류만 가능. 선형 모델보다 훨씬 빠름. 대용량 데이터셋과 고차원 데이터에 가능. 선형 모델보다 덜 정확함
# 4. 결정트리
#    매우 빠름. 데이터 스케일 조정이 필요 없음. 시각화하기 좋고 설명하기 쉬움.
# 5. 결정트리 앙상블 
#  5.1 랜덤 포레스트
#      결정 트리 하나보다 거의 항상 좋은 성능을 냄. 매우 안정적이고 강력함. 
#      데이터 스케일 조정 필요 없음. 고차원 희소 데이터에는 잘 안 맞음.
#  5.2 그래디언트 부스팅
#      랜덤 포레스트보다 조금 더 성능이 좋음. 랜덤 포레스트보다 학습은 느리나 예측은 빠르고 메모리를 조금 사용. 
#      랜덤 포레스트보다 매개변수 튜닝이 많이 필요함.
# 6. 커널서포트벡터머신
#    비슷한 의미의 특성으로 이뤄진 중간 규모 데이터셋에 잘 맞음. 데이터 스케일 조정 필요. 매개변수에 민감
# 7. 신경망
#    특별히 대용량 데이터셋에서 매우 복잡한 모델을 만들 수 있음. 
#    매개변수 선택과 데이터 스케일에 민감. 큰 모델은 학습이 오래 걸림.

